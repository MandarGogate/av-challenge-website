## Call for papers: 3rd COG-MHEAR Audio-Visual Speech Enhancement Challenge (AVSEC-3) 



The Audio-Visual Speech Enhancement Challenge (AVSEC) sets the first benchmark in the field of audio-visual speech enhancement, providing a carefully designed dataset and scalable protocol for human listening evaluation of audio-visual speech enhancement systems. Two previous successful editions of the Challenge (SLT 2022 and ASRU 2023) show a general trend of system improvement but indicate that an intelligibility gap remains when compared to clean speech.  


We will run a third edition of the challenge, AVSEC-3, in the first half of 2024.  Papers related to the challenge to be presented at a dedicated workshop with timing aligned to Interspeech 2024 in Greece.  The AVSEC results will also be announced at the workshop.  Furthermore, the workshop will showcase ongoing technology developments in audio-visual speech enhancement and to provide a space to reflect on the scope and limitations of current speech and hearing technologies. 


We invite submissions from participants of the second and third editions of the challenge, and also welcome submissions of related research topics, including but not limited to the following:


- Audio quality & intelligibility assessment of audio-visual speech enhancement systems.
- Objective metrics to predict quality & intelligibility from audio-visual stimuli.
- Human auditory-inspired models of multi-modal speech perception and enhancement.
- Real-time and low-latency approaches to audio-visual speech enhancement and separation.
- Energy-efficient audio-visual speech enhancement and separation methods.
- Machine learning for diverse target listeners and diverse listening scenarios.
- Understanding human speech perception in competing speaker scenarios.
- Clinical applications of audio-visual speech enhancement and separation (e.g. for hearing impaired listeners).
- Accessibility and human-centric factors in the design and evaluation of multi-modal hearing assistive technologies, including public perceptions, ethics considerations, standards, societal, economic and political impacts.


[//]: # (Important dates can be found [here.]&#40;https://challenge.cogmhear.org/#/important-dates&#41;)

**Important dates**

- 1st February 2024: Release of training and development data. 
- 1st February 2024: Release of baseline system. 
- 1st April 2024: Evaluation data release. 
- 1st April 2024: Leaderboard open for submissions. 
- 6th May 2024: Paper submission opens. 
- 20th June/2024: Deadline for challenge submissions and one-page system description submission.
- 28th June 2024: Paper submission closes. 
- 12th July: Acceptance notification. 
- 26th July: early release of evaluation results.
- 1st August 2024: camera-ready paper. 


**Scientific committee**

We are in the process of recruiting a scientific committee to contribute to the review process. 
This will be a balance of academics and industry experts from the speech and hearing communities, with a similar profile to that of our previously organised workshops: [Advances on multi-modal Hearing Assistive Technologies (AMHAT 2023)](https://cogmhear.org/amhat2023/) and [Multi-talker methods in speech processing](https://pjb56.github.io/multitalker/): 
 
Peter Derleth, Sonova 
Ben Milner, University of East Anglia, UK 
Jennifer Williams, University of Southampton, UK 
Emanuel Habets, University of Erlangen-Nuremberg, Germany 
Chi-Chun Lee, National Tsing Hua University, Taiwan 
Hadi Larijani, Glasgow Caledonian University, UK 
Erfan Loweimi, University of Cambridge and Edinburgh Napier University, UK 
Raza Varzandeh, University of Oldenburgh, Germany 
Jesper Jensen, Aalborg University, Denmark 
Sharon Gannot (Bar -Ilan University, Israel) 
Yong Xu, Tencent America, USA 
Dong Yu, Tencent AI Lab, China 
Daniel Michelsanti, Aalborg University, Denmark 
Volker Hohmann, University of Oldenburgh, Germany 
Marc Delcroix, NTT Communication Science Laboratories, Japan 
Zheng-Hua Tan, Aalborg University, Denmark 
Harish Chandra Dubey, Microsoft, USA 
Simon Doclo, University of Oldenburgh, Germany 
Kia Dashtipour, Edinburgh Napier University 
Hsin-Min Wang, Academia Sinica, Taiwan 
Mandar Gogate, Edinburgh Napier University, UK 
Jun-Cheng Chen, Academia Sinica, Taiwan 
Adeel Ahsan, University of Wolverhampton, UK 
Alex Casson, University of Manchester, UK 
Tharm Ratnarajah, University of Edinburgh, UK 
Jen-Cheng Hou, Academia Sinica, Taiwan 
Tughrul Arslan, University of Edinburgh, UK 
Shinji Watanabe, Carnegie Mellon University 
Nima Mesgarani, Columbia University, USA 
Jesper Jensen, Aalborg University, Denmark 
Qiang Huang, University of Sunderland, UK 
Bernd T. Meyer, University of Oldenburgh, Germany 
James M. Kates (University of Colorado, USA) 
Volker Hohmann (Carl von Ossietzky University of Oldenburg, Germany) 
